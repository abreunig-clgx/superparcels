{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import geopandas as gpd \n",
    "import os\n",
    "import pandas as pd \n",
    "from shapely.ops import nearest_points\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_distance(polygon1, polygon2):\n",
    "    # Calculate the minimum distance between two polygons\n",
    "    point1, point2 = nearest_points(polygon1, polygon2)\n",
    "    return point1.distance(point2)\n",
    "\n",
    "def compute_distance_matrix(polygons):\n",
    "    # Create a distance matrix between all polygons\n",
    "    num_polygons = len(polygons)\n",
    "    distance_matrix = np.zeros((num_polygons, num_polygons))\n",
    "    \n",
    "    for i in range(num_polygons):\n",
    "        for j in range(i + 1, num_polygons):\n",
    "            distance_matrix[i, j] = polygon_distance(polygons[i], polygons[j])\n",
    "            distance_matrix[j, i] = distance_matrix[i, j]  # Symmetry\n",
    "    \n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'D:\\Projects\\superparcels\\data\\Rural\\Crook_OR'\n",
    "output_dir = r'D:\\Projects\\superparcels\\data\\urban\\outputs\\dmatrix'\n",
    "parcels = gpd.read_file(os.path.join(data_dir, 'sp_sample_41013_cluster_canidates.shp'))\n",
    "utm = parcels.estimate_utm_crs().to_epsg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels = parcels.to_crs(epsg=utm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OWNER\n",
       "BRADLEYSANTUCCI                        24\n",
       "CONNIE MHATFIELD                       18\n",
       "R HORTON INCD R HORTON INC-PORTLAND    18\n",
       "JOANNWEAVER                            14\n",
       "STEPHEN TGILLEN                        14\n",
       "                                       ..\n",
       "IRA GESSOE                              2\n",
       "MARY DMAYFIELD                          2\n",
       "SUSAN KCRAWFORD                         2\n",
       "DUSTINCOLLINS                           2\n",
       "IMPROVEMENTIDLEWAY                      2\n",
       "Name: count, Length: 1226, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcels['OWNER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique owners: 1226\n"
     ]
    }
   ],
   "source": [
    "unique_owners = parcels['OWNER'].unique()\n",
    "print('Number of unique owners:', len(unique_owners))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_parcel_data = gpd.GeoDataFrame()\n",
    "single_parcel_data = gpd.GeoDataFrame()\n",
    "cluster_counts_dict = {}    \n",
    "for owner in unique_owners:\n",
    "    if owner != 'L RKOPCINSKI':\n",
    "        continue\n",
    "    \n",
    "    owner_parcels = parcels[parcels['OWNER'] == owner]\n",
    "    polygons = owner_parcels['geometry'].to_list()\n",
    "    distance_matrix = compute_distance_matrix(polygons)\n",
    "    \n",
    "    if distance_matrix.shape[0] < 3: # only two parcels\n",
    "        continue\n",
    "    \n",
    "    if np.all(distance_matrix == 0):\n",
    "        min_valid_distance = 3\n",
    "        optimal_distance = 3\n",
    "    else:\n",
    "        min_valid_distance = np.round(np.min(distance_matrix[distance_matrix > 0]))\n",
    "\n",
    "        # Assuming distance_matrix is the precomputed distance matrix\n",
    "        neighbors = NearestNeighbors(n_neighbors=sample_size, metric='precomputed')\n",
    "        neighbors_fit = neighbors.fit(distance_matrix)\n",
    "\n",
    "        try:\n",
    "            distances, indices = neighbors_fit.kneighbors(distance_matrix)\n",
    "        except ValueError:\n",
    "            print(f'Error: Not enough samples in {owner}')\n",
    "            print(distance_matrix)\n",
    "            sys.exit()\n",
    "\n",
    "        # Sort distances to the k-th nearest neighbor\n",
    "        sorted_distances = np.sort(distances[:, sample_size-1])\n",
    "        smooth_dist = uniform_filter1d(sorted_distances, size=5)\n",
    "        difference = np.diff(smooth_dist)\n",
    "        difference2 = np.diff(difference)\n",
    "        elbow_index = np.argmax(difference2) + 1\n",
    "        optimal_distance = np.round(sorted_distances[elbow_index])\n",
    "        if optimal_distance == 0: # adjacent parcels\n",
    "                optimal_distance = 1\n",
    "\n",
    "        distance_cap = 250\n",
    "        if optimal_distance > distance_cap:\n",
    "            optimal_distance = distance_cap\n",
    "            \n",
    "        #print(f'Optimal distance: {optimal_distance}')\n",
    "    \n",
    "    dbscan = DBSCAN(eps=optimal_distance, min_samples=sample_size, metric='precomputed')\n",
    "    clusters = dbscan.fit_predict(distance_matrix)\n",
    "    owner_parcels['cluster'] = clusters \n",
    "    owner_parcels['area'] = owner_parcels['geometry'].area\n",
    "    counts = owner_parcels['cluster'].value_counts()\n",
    "    \n",
    "    #single_parcel_clusters = counts[counts == 1].index\n",
    "    #low_parcel_clusters = counts[counts < 3].index\n",
    "    outliers = counts[counts.index == -1].index\n",
    "    single_parcel_filter_ids = set(list(outliers))\n",
    "        \n",
    "    single_parcel_filter = owner_parcels[owner_parcels['cluster'].isin(single_parcel_filter_ids)]\n",
    "    single_parcel_data = pd.concat([single_parcel_data, single_parcel_filter], ignore_index=True)\n",
    "    \n",
    "    cluster_filter = owner_parcels[~owner_parcels['cluster'].isin(single_parcel_filter_ids)]\n",
    "    if len(cluster_filter) > 0:\n",
    "        cluster_counts_dict[owner] = sum(counts.to_list())\n",
    "        cluster_filter['buff_dist'] = optimal_distance\n",
    "        clustered_parcel_data = pd.concat([clustered_parcel_data, cluster_filter], ignore_index=True)\n",
    "    #print('______________________________________________________________________________________')\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Owner containing two parcels with their respective distances to eachother (meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,  12.19161688, 121.90883318],\n",
       "       [  0.        ,  12.19161688, 121.90818142],\n",
       "       [  0.        ,   9.39928466,  12.19138101],\n",
       "       [  0.        ,  11.61237218,  12.19138101],\n",
       "       [  0.        ,   9.39928466,  11.61237218]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.61237218,  12.19138101,  12.19138101, 121.90818142,\n",
       "       121.90883318])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-664.96898359, -687.77856297,  -22.80957938])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_parcel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cluster ID\n",
    "clustered_parcel_data['cluster_ID'] = clustered_parcel_data['OWNER'] + '_' + clustered_parcel_data['cluster'].astype(str)\n",
    "single_parcel_data['cluster_ID'] = single_parcel_data['OWNER'] + '_' + single_parcel_data['cluster'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_parcel_data['count'] = clustered_parcel_data['OWNER'].map(cluster_counts_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_dissolve = clustered_parcel_data.dissolve(by='cluster_ID').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_ID</th>\n",
       "      <th>geometry</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>OWNER</th>\n",
       "      <th>duplicate_</th>\n",
       "      <th>duplicat_1</th>\n",
       "      <th>classifica</th>\n",
       "      <th>classifi_1</th>\n",
       "      <th>cluster</th>\n",
       "      <th>area</th>\n",
       "      <th>buff_dist</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L RKOPCINSKI_0</td>\n",
       "      <td>MULTIPOLYGON (((706935.316 4928108.743, 706687...</td>\n",
       "      <td>41013</td>\n",
       "      <td>L RKOPCINSKI</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Class2: Duplicate Owner</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>199568.267682</td>\n",
       "      <td>122.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cluster_ID                                           geometry   FIPS  \\\n",
       "0  L RKOPCINSKI_0  MULTIPOLYGON (((706935.316 4928108.743, 706687...  41013   \n",
       "\n",
       "          OWNER  duplicate_  duplicat_1               classifica  classifi_1  \\\n",
       "0  L RKOPCINSKI           1           0  Class2: Duplicate Owner           2   \n",
       "\n",
       "   cluster           area  buff_dist  count  \n",
       "0        0  199568.267682      122.0      5  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcel_dissolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to buffer the geometry by its buff_dist\n",
    "def buffer_geometry(geometry, buff_dist):\n",
    "    return geometry.buffer(buff_dist)\n",
    "\n",
    "# Use map to apply the buffer_geometry function to each geometry and buff_dist\n",
    "parcel_dissolve['geometry'] = list(map(buffer_geometry, parcel_dissolve['geometry'], parcel_dissolve['buff_dist']))\n",
    "parcel_dissolve['geometry'] = list(map(buffer_geometry, parcel_dissolve['geometry'], -parcel_dissolve['buff_dist']))\n",
    "parcel_dissolve = parcel_dissolve.explode(ignore_index=True)\n",
    "parcel_dissolve['sp_id'] = parcel_dissolve['cluster_ID'] + \"_\" + parcel_dissolve.groupby('cluster_ID').cumcount().astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_dissolve.to_file(os.path.join(data_dir, 'parcel_dissolve.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_dissolve['area'] = parcel_dissolve['geometry'].area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_ID\n",
       "COLEMANFOLEY_0    1.592413e+07\n",
       "Name: area, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcel_dissolve.groupby('cluster_ID')['area'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_area = parcel_dissolve.groupby('cluster_ID')['area'].mean()\n",
    "super_parcel_ids = mean_area[mean_area > 100000].index\n",
    "super_parcels = parcel_dissolve[parcel_dissolve['cluster_ID'].isin(super_parcel_ids)]\n",
    "super_parcels = super_parcels[['cluster_ID', 'OWNER', 'area', 'buff_dist', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to buffer the geometry by its buff_dist\n",
    "def buffer_geometry(geometry, buff_dist):\n",
    "    return geometry.buffer(buff_dist)\n",
    "\n",
    "# Use map to apply the buffer_geometry function to each geometry and buff_dist\n",
    "super_parcels['geometry'] = list(map(buffer_geometry, super_parcels['geometry'], super_parcels['buff_dist']))\n",
    "super_parcels['geometry'] = list(map(buffer_geometry, super_parcels['geometry'], -super_parcels['buff_dist']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_parcels['geometry'] = super_parcels['geometry'].buffer(dbscan_distance)\n",
    "super_parcels['geometry'] = super_parcels['geometry'].buffer(-dbscan_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_parcels.to_file(os.path.join(data_dir, 'super_parcels_rbuff_var.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
