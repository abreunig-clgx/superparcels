{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN, HDBSCAN\n",
    "import numpy as np\n",
    "import geopandas as gpd \n",
    "import os\n",
    "import pandas as pd \n",
    "from shapely import concave_hull, convex_hull, segmentize, minimum_rotated_rectangle\n",
    "from shapely.ops import nearest_points\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_distance = 50\n",
    "density_threshold = 10\n",
    "concave_ratio = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_distance(polygon1, polygon2):\n",
    "    # Calculate the minimum distance between two polygons\n",
    "    point1, point2 = nearest_points(polygon1, polygon2)\n",
    "    return point1.distance(point2)\n",
    "\n",
    "def compute_distance_matrix(polygons):\n",
    "    # Create a distance matrix between all polygons\n",
    "    num_polygons = len(polygons)\n",
    "    distance_matrix = np.zeros((num_polygons, num_polygons))\n",
    "    \n",
    "    for i in range(num_polygons):\n",
    "        for j in range(i + 1, num_polygons):\n",
    "            distance_matrix[i, j] = polygon_distance(polygons[i], polygons[j])\n",
    "            distance_matrix[j, i] = distance_matrix[i, j]  # Symmetry\n",
    "    \n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'D:\\Projects\\superparcels\\data\\urban'\n",
    "output_dir = r'D:\\Projects\\superparcels\\data\\urban\\outputs\\dmatrix'\n",
    "parcels = gpd.read_file(os.path.join(data_dir, 'sp_sample_08013_cluster_canidates.shp'))\n",
    "utm = parcels.estimate_utm_crs().to_epsg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels = parcels.to_crs(epsg=utm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique owners: 1396\n"
     ]
    }
   ],
   "source": [
    "unique_owners = parcels['OWNER'].unique()\n",
    "print('Number of unique owners:', len(unique_owners))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OWNER\n",
       "STEPHEN DTEBO           25\n",
       "HENRY PVELLANDI         14\n",
       "CHRISTOPHER JWALKER     13\n",
       "DAVID NLARSON           13\n",
       "SOTERIOSPALMOS           9\n",
       "                        ..\n",
       "MICHAEL RHOWARD          1\n",
       "MARCPATTERSON            1\n",
       "HEATHERDWIGHT            1\n",
       "MANOUCHEHRZIRAKZADEH     1\n",
       "DAVID WPAULE             1\n",
       "Name: count, Length: 1396, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcels['OWNER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OWNER: MARIJETERELLEN\n",
      "[[   0.         3593.54426338]\n",
      " [3593.54426338    0.        ]]\n"
     ]
    }
   ],
   "source": [
    "clustered_parcel_data = gpd.GeoDataFrame()\n",
    "single_parcel_data = gpd.GeoDataFrame()\n",
    "for owner in unique_owners:\n",
    "    print(f'OWNER: {owner}')\n",
    "    owner_parcels = parcels[parcels['OWNER'] == owner]\n",
    "    polygons = owner_parcels['geometry'].to_list()\n",
    "    distance_matrix = compute_distance_matrix(polygons)\n",
    "\n",
    "    print(distance_matrix)\n",
    "\n",
    "    break\n",
    "\n",
    "\n",
    "    dbscan = DBSCAN(eps=dbscan_distance, min_samples=2, metric='precomputed')\n",
    "    clusters = dbscan.fit_predict(distance_matrix)\n",
    "    owner_parcels['cluster'] = clusters \n",
    "    counts = owner_parcels['cluster'].value_counts()\n",
    "    #print(f'Cluster Counts: {counts}')\n",
    "    single_parcel_clusters = counts[counts == 1].index\n",
    "    single_parcel_outliers = counts[counts.index == -1].index\n",
    "    single_parcel_filter_ids = list(single_parcel_clusters) + list(single_parcel_outliers)\n",
    "        \n",
    "    single_parcel_filter = owner_parcels[owner_parcels['cluster'].isin(single_parcel_filter_ids)]\n",
    "    single_parcel_data = pd.concat([single_parcel_data, single_parcel_filter], ignore_index=True)\n",
    "    \n",
    "    cluster_filter = owner_parcels[(~owner_parcels['cluster'].isin(single_parcel_clusters))&(owner_parcels['cluster'] != -1)]\n",
    "    clustered_parcel_data = pd.concat([clustered_parcel_data, cluster_filter], ignore_index=True)\n",
    "    print('______________________________________________________________________________________')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of Owner containing two parcels with their respective distances to eachother (meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cluster ID\n",
    "clustered_parcel_data['cluster_ID'] = clustered_parcel_data['OWNER'] + '_' + clustered_parcel_data['cluster'].astype(str)\n",
    "single_parcel_data['cluster_ID'] = single_parcel_data['OWNER'] + '_' + single_parcel_data['cluster'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_dissolve = clustered_parcel_data.dissolve(by='cluster_ID').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_parcels = parcel_dissolve.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# densify the super parcels\n",
    "super_parcels['geometry'] = super_parcels['geometry'].apply(lambda x: segmentize(x, density_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_parcels['geometry'] = super_parcels['geometry'].apply(lambda x: concave_hull(x, ratio=concave_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, parcel in super_parcels.iterrows():\n",
    "    parcel_geom = gpd.GeoDataFrame(geometry=[parcel.geometry])\n",
    "    parcel_id = parcel['cluster_ID']    \n",
    "    other_sp = super_parcels.loc[super_parcels['cluster_ID'] != parcel_id]\n",
    "    other_single = single_parcel_data.loc[single_parcel_data['cluster_ID'] != parcel_id]\n",
    "    \n",
    "    other_sp_union = gpd.GeoDataFrame(geometry=[other_sp.unary_union])\n",
    "    other_single_union = gpd.GeoDataFrame(geometry=[other_single.unary_union])\n",
    "    other_union = pd.concat([other_sp_union, other_single_union], ignore_index=True)\n",
    "\n",
    "    parcel_clip = (gpd.overlay(parcel_geom, other_union, how='difference')\n",
    "                    .explode(ignore_index=True)\n",
    "                    .reset_index(drop=True))\n",
    "\n",
    "    parcel_clip['cluster_ID'] = parcel_id\n",
    "    parcel_clip['OWNER'] = parcel['OWNER']\n",
    "\n",
    "    # drop correspnding row in super_parcels\n",
    "    super_parcels = super_parcels[super_parcels['cluster_ID'] != parcel_id]\n",
    "    super_parcels = pd.concat([super_parcels, parcel_clip], ignore_index=True) # add parcel clip to super_parcels\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_parcels = super_parcels.explode(ignore_index=True)\n",
    "super_parcels['sp_ID'] = super_parcels['cluster_ID'] + \"_\" + super_parcels.groupby('cluster_ID').cumcount().astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_parcels[['sp_ID', 'cluster_ID', 'OWNER', 'geometry']].to_file(os.path.join(output_dir, f'sp_dbscan{dbscan_distance}-cr{concave_ratio}-dens{density_threshold}.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>cnty_code</th>\n",
       "      <th>OWNER</th>\n",
       "      <th>std_addr</th>\n",
       "      <th>duplicate_</th>\n",
       "      <th>duplicat_1</th>\n",
       "      <th>duplicat_2</th>\n",
       "      <th>classifica</th>\n",
       "      <th>classifi_1</th>\n",
       "      <th>geometry</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>MARIJETERELLEN</td>\n",
       "      <td>501 EVERGREEN AVE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class3: Duplicate Owner &amp; Unique Address, Geom...</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((475278.750 4431268.298, 475278.750 4...</td>\n",
       "      <td>-1</td>\n",
       "      <td>MARIJETERELLEN_-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>MARIJETERELLEN</td>\n",
       "      <td>1235 BASELINE RD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class3: Duplicate Owner &amp; Unique Address, Geom...</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((476412.821 4427818.727, 476412.769 4...</td>\n",
       "      <td>-1</td>\n",
       "      <td>MARIJETERELLEN_-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>JASONCOTRELL</td>\n",
       "      <td>640 LARAMIE BLVD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class3: Duplicate Owner &amp; Unique Address, Geom...</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((475550.330 4435190.856, 475557.271 4...</td>\n",
       "      <td>-1</td>\n",
       "      <td>JASONCOTRELL_-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_code  cnty_code           OWNER           std_addr  duplicate_  \\\n",
       "0           8         13  MARIJETERELLEN  501 EVERGREEN AVE           1   \n",
       "1           8         13  MARIJETERELLEN   1235 BASELINE RD           1   \n",
       "2           8         13    JASONCOTRELL   640 LARAMIE BLVD           1   \n",
       "\n",
       "   duplicat_1  duplicat_2                                         classifica  \\\n",
       "0           0           0  Class3: Duplicate Owner & Unique Address, Geom...   \n",
       "1           0           0  Class3: Duplicate Owner & Unique Address, Geom...   \n",
       "2           0           0  Class3: Duplicate Owner & Unique Address, Geom...   \n",
       "\n",
       "   classifi_1                                           geometry  cluster  \\\n",
       "0           3  POLYGON ((475278.750 4431268.298, 475278.750 4...       -1   \n",
       "1           3  POLYGON ((476412.821 4427818.727, 476412.769 4...       -1   \n",
       "2           3  POLYGON ((475550.330 4435190.856, 475557.271 4...       -1   \n",
       "\n",
       "          cluster_ID  \n",
       "0  MARIJETERELLEN_-1  \n",
       "1  MARIJETERELLEN_-1  \n",
       "2    JASONCOTRELL_-1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_parcel_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_parcel_data.to_file(os.path.join(output_dir, f'single_parcels.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_parcels = gpd.read_file(os.path.join(data_dir, f'super_parcels_cleaned_{dbscan_distance}.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_parcels = super_parcels[['cluster_ID', 'OWNER', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_join = gpd.sjoin(super_parcels, parcels)\n",
    "sp_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_join[['cluster_ID', 'OWNER_left', 'index_right', 'geometry']].to_file(os.path.join(data_dir, f'super_parcels_cleaned_{dbscan_distance}_join.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_parcel_ids = sp_join.groupby('cluster_ID')['index_right'].apply(list)\n",
    "cluster_to_parcel_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick up here, remove multiple small sliver polygons, and then rerun the above code. add a condition to only grab matching ownership before dissolve the sp_geom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_parcels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_super_parcels = gpd.GeoDataFrame()\n",
    "for cluster_id, parcel_ids in cluster_to_parcel_ids.items():\n",
    "    sp_geom = super_parcels[super_parcels['cluster_ID'] == cluster_id]\n",
    "    \n",
    "    \n",
    "    for parcel_id in set(parcel_ids):\n",
    "        print(f'{cluster_id} -> {parcel_id}')\n",
    "        parcel_geom = parcels[parcels.index == parcel_id]\n",
    "        if parcel_geom['OWNER'].values[0] == sp_join[sp_join['index_right'] == parcel_id]['OWNER_left'].values[0]:\n",
    "            print('Owner match')\n",
    "            sp_geom = pd.concat([sp_geom, parcel_geom], ignore_index=True)\n",
    "            print('___')\n",
    "        else:\n",
    "            print('Owner mismatch')\n",
    "            print('___')\n",
    "            continue\n",
    "        \n",
    "    sp_geom_dissolve = sp_geom.dissolve().reset_index()[['cluster_ID', 'OWNER', 'geometry']]\n",
    "    # drop cluster_id from super parcel\n",
    "    super_parcels = super_parcels[super_parcels['cluster_ID'] != cluster_id]\n",
    "    # add new super parcel\n",
    "    super_parcels = pd.concat([super_parcels, sp_geom_dissolve], ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_parcels.to_file(os.path.join(data_dir, f'super_parcels_cleaned_{dbscan_distance}_final.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_parcel_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
