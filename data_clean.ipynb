{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "import glob\n",
    "from typing import Optional, Union, Dict, List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_conversion(csv_path, crs='EPSG:4326', dtypes=None):\n",
    "    \"\"\"\n",
    "    Convert a CSV file to a geodataframe\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, dtype=dtypes)\n",
    "    # Convert the geometry column to a geodataframe\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=df['geometry'].apply(wkt.loads), crs=crs)\n",
    "\n",
    "    return gdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r'D:\\Projects\\superparcels\\data\\abreunig_pocs_spatialrecord_polygon_superparcel_urban.csv'\n",
    "output_dir = r'D:\\Projects\\superparcels\\data\\Urban'\n",
    "county_names = {\n",
    "    '06075': 'San_Fran_CA',\n",
    "    '06001': 'Alameda_CA',\n",
    "    '08031': 'Denver_CO',\n",
    "    '48113': 'Dallas_TX',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csv_conversion(csv_path, dtype={'FIPS': str})\n",
    "fips = df['FIPS'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['06075', '08031', '06001', '48113'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for fid in fips:\n",
    "    print(fid)\n",
    "    df_fid = df[df['FIPS'] == fid]\n",
    "    fid_dir = os.path.join(output_dir, county_names[fid])\n",
    "    if not os.path.exists(fid_dir):\n",
    "        os.makedirs(fid_dir)\n",
    "\n",
    "    df_fid.to_file(os.path.join(fid_dir, f'sp_sample_{fid}.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate geometries and find canidate parcels for clustering POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_duplicates(df, fields):\n",
    "    \"\"\"\n",
    "    Classifies the rows of a DataFrame based on duplicate status for any number of fields.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    fields (list of str): List of column names to check for duplicates.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: Value counts of each classification.\n",
    "    \"\"\"\n",
    "    # Identify duplicates for each field and store in a new column\n",
    "    for field in fields:\n",
    "        df[f'duplicate_{field}'] = df.duplicated(subset=[field], keep=False)\n",
    "\n",
    "    # Create a classification column based on the duplication status of each field\n",
    "    def classify_row(row):\n",
    "        classification = []\n",
    "        for field in fields:\n",
    "            if row[f'duplicate_{field}']:\n",
    "                classification.append(f'Duplicate {field}')\n",
    "            else:\n",
    "                classification.append(f'Unique {field}')\n",
    "        return ', '.join(classification)\n",
    "\n",
    "    df['classification'] = df.apply(classify_row, axis=1)\n",
    "    df['classify_codes'] = df['classification'].astype('category').cat.codes\n",
    "\n",
    "    # Count the occurrences of each classification\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# fields = ['OWNER', 'std_addr', 'geometry']\n",
    "# matrix = classify_duplicates(df, fields)\n",
    "# print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codes_to_shp(df, id_field: str, code_field: str, cluster_canidate_codes: Optional[List] = []):\n",
    "    \"\"\"\n",
    "    Convert a DataFrame to a shapefile based on classification codes.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    id_field (str): Name of the field to use as the unique identifier.\n",
    "    code_field (str): Name of the field containing the classification codes.\n",
    "    cluster_canidate_codes (list of int): List of classification codes to use as cluster candidates.\n",
    "    \"\"\"\n",
    "\n",
    "    for code in class_codes:\n",
    "        gdf = df[df[code_field] == code]\n",
    "        gdf.to_file(os.path.join(data_dir, f'sp_sample_{id_field}_{code}.shp'))\n",
    "\n",
    "    for code in cluster_canidate_codes:\n",
    "        gdf = df[df[code_field] == code]\n",
    "        print(f'Cluster canidates from code {code}: {gdf['classification'].unique()}')\n",
    "        gdf.to_file(os.path.join(data_dir, f'sp_sample_{id_field}_cluster_candidates.shp'))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06075\n",
      "classification\n",
      "Unique OWNER, Unique geometry          65119\n",
      "Unique OWNER, Duplicate geometry       31794\n",
      "Duplicate OWNER, Unique geometry       17973\n",
      "Duplicate OWNER, Duplicate geometry     6132\n",
      "Name: count, dtype: int64\n",
      "classify_codes\n",
      "1    17973\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for fid in fips:\n",
    "    print(f'Processing {fid}')\n",
    "    county_name = county_names[fid]\n",
    "    file_path = os.path.join(output_dir, f'{county_name}\\sp_sample*.shp')\n",
    "\n",
    "    if len(glob.glob(file_path)) == 0:\n",
    "        print(file_path)\n",
    "        continue\n",
    "\n",
    "    df = gpd.read_file(fi)\n",
    "\n",
    "    df = classify_duplicates(df, fields=['OWNER', 'geometry'])\n",
    "    print(df['classification'].value_counts())\n",
    "    print(df['classify_codes'].value_counts())\n",
    "\n",
    "    canidate_df = df[df['classification'] == 'Duplicate OWNER, Unique geometry']\n",
    "\n",
    "    codes_to_shp(df, id_field='FIPS', code_field='classify_codes', cluster_canidate_codes=canidate_df['classify_codes'].unique())\n",
    "    print('_____________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
