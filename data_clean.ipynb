{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "import glob\n",
    "from typing import Optional, Union, Dict, List, Any\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_conversion(csv_path, crs='EPSG:4326', dtypes=None):\n",
    "    \"\"\"\n",
    "    Convert a CSV file to a geodataframe\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, dtype=dtypes)\n",
    "    # Convert the geometry column to a geodataframe\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=df['geometry'].apply(wkt.loads), crs=crs)\n",
    "\n",
    "    return gdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r'<PATH/TO/CSV>'\n",
    "output_dir = r'<PATH/>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = csv_conversion(csv_path, dtypes={'FIPS': str})\n",
    "county_names = {\n",
    "    '06075': 'San_Fran_CA',\n",
    "    '06001': 'Alameda_CA',\n",
    "    '08031': 'Denver_CO',\n",
    "    '48113': 'Dallas_TX',\n",
    "    '41013': 'Crook_OR',\n",
    "    '20097': 'Kiowa_KS',\n",
    "    '55107': 'Rusk_WI',\n",
    "    '35051': 'Sierra_NM',\n",
    "\n",
    "}\n",
    "fips = df['FIPS'].unique()\n",
    "fips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv to county raw shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fid in fips:\n",
    "    print(fid)\n",
    "    df_fid = df[df['FIPS'] == fid]\n",
    "    fid_dir = os.path.join(output_dir, county_names[fid])\n",
    "    if not os.path.exists(fid_dir):\n",
    "        os.makedirs(fid_dir)\n",
    "\n",
    "    df_fid.to_file(os.path.join(fid_dir, f'sp_sample_{fid}.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate geometries and find canidate parcels for clustering POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_duplicates(df, fields):\n",
    "    \"\"\"\n",
    "    Classifies the rows of a DataFrame based on duplicate status for any number of fields.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    fields (list of str): List of column names to check for duplicates.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: Value counts of each classification.\n",
    "    \"\"\"\n",
    "    # Identify duplicates for each field and store in a new column\n",
    "    for field in fields:\n",
    "        df[f'duplicate_{field}'] = df.duplicated(subset=[field], keep=False)\n",
    "\n",
    "    # Create a classification column based on the duplication status of each field\n",
    "    def classify_row(row):\n",
    "        classification = []\n",
    "        for field in fields:\n",
    "            if row[f'duplicate_{field}']:\n",
    "                classification.append(f'Duplicate {field}')\n",
    "            else:\n",
    "                classification.append(f'Unique {field}')\n",
    "        return ', '.join(classification)\n",
    "\n",
    "    df['classification'] = df.apply(classify_row, axis=1)\n",
    "    df['classify_codes'] = df['classification'].astype('category').cat.codes\n",
    "\n",
    "    # Count the occurrences of each classification\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codes_to_shp(df, output_dir: str, id_field: str, code_field: str, cluster_canidate_codes: Optional[List] = []):\n",
    "    \"\"\"\n",
    "    Convert a DataFrame to a shapefile based on classification codes.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the data.\n",
    "    id_field (str): Name of the field to use as the unique identifier.\n",
    "    code_field (str): Name of the field containing the classification codes.\n",
    "    cluster_canidate_codes (list of int): List of classification codes to use as cluster candidates.\n",
    "    \"\"\"\n",
    "    class_codes = df[code_field].unique()\n",
    "    for code in class_codes:\n",
    "        gdf = df[df[code_field] == code]\n",
    "        gdf.to_file(os.path.join(output_dir, f'sp_sample_{id_field}_{code}.shp'))\n",
    "\n",
    "    for code in cluster_canidate_codes:\n",
    "        gdf = df[df[code_field] == code]\n",
    "        gdf.to_file(os.path.join(output_dir, f'sp_sample_{id_field}_cluster_candidates.shp'))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mcolors.ListedColormap(['red', 'blue', 'green', 'yellow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fid in fips:\n",
    "    print(f'Processing {fid}')\n",
    "    if fid != '08031':\n",
    "        continue\n",
    "    county_name = county_names[fid]\n",
    "    file_path = os.path.join(output_dir, f'{county_name}\\sp_sample*.shp')\n",
    "\n",
    "    if len(glob.glob(file_path)) == 0:\n",
    "        print(file_path)\n",
    "        continue\n",
    "\n",
    "    df = gpd.read_file(glob.glob(file_path)[0])\n",
    "\n",
    "    df = classify_duplicates(df, fields=['OWNER', 'geometry'])\n",
    "    print(df['classification'].value_counts())\n",
    "    #print(df['classify_codes'].value_counts())\n",
    "    # visualize the data using matplotlib\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    df.plot(column='classification', ax=ax, legend=True, cmap=cmap)\n",
    "    ax.set_title(f'{county_name}')\n",
    "   \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    canidate_df = df[df['classification'] == 'Duplicate OWNER, Unique geometry']\n",
    "\n",
    "    codes_to_shp(\n",
    "        df,\n",
    "        output_dir=os.path.join(output_dir, county_name),\n",
    "        id_field=fid, \n",
    "        code_field='classify_codes', \n",
    "        cluster_canidate_codes=canidate_df['classify_codes'].unique()\n",
    "        )\n",
    "    print('_____________________________')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # add legend\n",
    "    # plot the data where duplicate owner, unique geometry is red and unique owner, duplicate geometry is blue\n",
    "    #df[df['classification'] == 'Duplicate OWNER, Unique geometry'].plot(ax=ax, color='red', label='Duplicate OWNER, Unique geometry', legend=True)\n",
    "    #df[df['classification'] == 'Unique OWNER, Unique geometry'].plot(ax=ax, color='blue', label='Unique OWNER, Duplicate geometry', legend=True)\n",
    "    \n",
    "    # add a title\n",
    "    #ax.set_title(f'{county_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
