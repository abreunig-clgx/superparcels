{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'D:\\Projects\\superparcels\\data\\abreunig_pocs_spatialrecord_polygon_superparcel_rural.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'D:\\Projects\\superparcels\\data\\Rural'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path, dtype={'FIPS': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fips = df['FIPS'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['55107', '20097', '41013', '35051'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55107\n",
      "20097\n",
      "41013\n",
      "35051\n"
     ]
    }
   ],
   "source": [
    "for fip in fips:\n",
    "    print(fip)\n",
    "    df_fip = df[df['FIPS'] == fip]\n",
    "    gdf = gpd.GeoDataFrame(df_fip, geometry=df_fip['geometry'].apply(wkt.loads), crs=4326)\n",
    "    gdf.to_file(os.path.join(data_dir, f'sp_sample_{fip}.shp'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean parcel urban and remove duplicate geometries for clustering POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r'D:\\Projects\\superparcels\\data\\Rural'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\superparcels\\data\\Rural\\sp_sample_20097.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abreunig\\AppData\\Local\\Temp\\2\\ipykernel_10820\\801280174.py:30: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  code.to_file(os.path.join(input_dir, f'sp_sample_{fips}_code{codes}.shp'))\n",
      "C:\\Users\\abreunig\\AppData\\Local\\Temp\\2\\ipykernel_10820\\801280174.py:30: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  code.to_file(os.path.join(input_dir, f'sp_sample_{fips}_code{codes}.shp'))\n",
      "C:\\Users\\abreunig\\AppData\\Local\\Temp\\2\\ipykernel_10820\\801280174.py:34: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  cluster.to_file(os.path.join(input_dir, f'sp_sample_{fips}_cluster_canidates.shp'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\superparcels\\data\\Rural\\sp_sample_35051.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abreunig\\AppData\\Local\\Temp\\2\\ipykernel_10820\\801280174.py:30: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  code.to_file(os.path.join(input_dir, f'sp_sample_{fips}_code{codes}.shp'))\n",
      "C:\\Users\\abreunig\\AppData\\Local\\Temp\\2\\ipykernel_10820\\801280174.py:30: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  code.to_file(os.path.join(input_dir, f'sp_sample_{fips}_code{codes}.shp'))\n",
      "C:\\Users\\abreunig\\AppData\\Local\\Temp\\2\\ipykernel_10820\\801280174.py:34: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  cluster.to_file(os.path.join(input_dir, f'sp_sample_{fips}_cluster_canidates.shp'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\superparcels\\data\\Rural\\sp_sample_41013.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abreunig\\AppData\\Local\\Temp\\2\\ipykernel_10820\\801280174.py:30: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  code.to_file(os.path.join(input_dir, f'sp_sample_{fips}_code{codes}.shp'))\n",
      "C:\\Users\\abreunig\\AppData\\Local\\Temp\\2\\ipykernel_10820\\801280174.py:30: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  code.to_file(os.path.join(input_dir, f'sp_sample_{fips}_code{codes}.shp'))\n",
      "C:\\Users\\abreunig\\AppData\\Local\\Temp\\2\\ipykernel_10820\\801280174.py:34: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  cluster.to_file(os.path.join(input_dir, f'sp_sample_{fips}_cluster_canidates.shp'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\superparcels\\data\\Rural\\sp_sample_55107.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abreunig\\AppData\\Local\\Temp\\2\\ipykernel_10820\\801280174.py:30: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  code.to_file(os.path.join(input_dir, f'sp_sample_{fips}_code{codes}.shp'))\n",
      "C:\\Users\\abreunig\\AppData\\Local\\Temp\\2\\ipykernel_10820\\801280174.py:30: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  code.to_file(os.path.join(input_dir, f'sp_sample_{fips}_code{codes}.shp'))\n",
      "C:\\Users\\abreunig\\AppData\\Local\\Temp\\2\\ipykernel_10820\\801280174.py:34: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  cluster.to_file(os.path.join(input_dir, f'sp_sample_{fips}_cluster_canidates.shp'))\n"
     ]
    }
   ],
   "source": [
    "for fi in glob.glob(os.path.join(input_dir, '*.shp')):\n",
    "    print(fi)\n",
    "    fips = os.path.basename(fi).split('_')[-1].split('.')[0]\n",
    "    \n",
    "    df = gpd.read_file(fi)\n",
    "    # Identify duplicate owners, addresses, and geometries\n",
    "    df['duplicate_owner'] = df.duplicated(subset=['OWNER'], keep=False)\n",
    "    df['duplicate_geometry'] = df.duplicated(subset=['geometry'], keep=False)\n",
    "\n",
    "    # Create a classification column based on duplication status (with geometry)\n",
    "    df['classification'] = df.apply(\n",
    "        lambda row: (\n",
    "            'Class1: Duplicate Owner & Geometry' if row['duplicate_owner'] and row['duplicate_geometry'] else\n",
    "            'Class2: Duplicate Owner' if row['duplicate_owner'] else\n",
    "            'Class3: Duplicate Geometry' if row['duplicate_geometry'] else\n",
    "            'Class4: Unique'\n",
    "        ), axis=1\n",
    "    )\n",
    "\n",
    "    # create clasification codes\n",
    "    df['classification_code'] = df['classification'].apply(lambda x: x.split(':')[0][5])\n",
    "    df['classification_code'] = df['classification_code'].astype(int)\n",
    "    \n",
    "    class_codes = [1, 2, 3, 4]\n",
    "\n",
    "    for codes in class_codes:\n",
    "        code = df[df['classification_code'] == codes]\n",
    "        if len(code) == 0:\n",
    "            continue\n",
    "        code.to_file(os.path.join(input_dir, f'sp_sample_{fips}_code{codes}.shp'))\n",
    "\n",
    "    cluster_canidate_code = 2\n",
    "    cluster = df[df['classification_code'] == cluster_canidate_code]\n",
    "    cluster.to_file(os.path.join(input_dir, f'sp_sample_{fips}_cluster_canidates.shp'))\n",
    "\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
